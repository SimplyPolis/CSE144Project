{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-06-04T17:41:48.277573Z",
     "start_time": "2024-06-04T17:41:48.274104Z"
    }
   },
   "source": [
    "from torch import nn, optim\n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets import ImageFolder"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T17:41:48.286286Z",
     "start_time": "2024-06-04T17:41:48.283094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print('Running on MPS')\n",
    "elif torch.cuda.is_available():\n",
    "    os.environ[\"USE_FLASH_ATTENTION\"] = \"1\"\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    print('Running on CUDA')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Running on CPU')"
   ],
   "id": "59afc4b266dcf5a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CUDA\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T17:41:48.624961Z",
     "start_time": "2024-06-04T17:41:48.294173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "model=resnet50(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "model = model.to(device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())"
   ],
   "id": "e432550f959d05ae",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T17:41:48.664023Z",
     "start_time": "2024-06-04T17:41:48.628970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    ImageFolder(\"Brain_Tumor_Datasets_Classified\\\\train\",transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   \n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "])),\n",
    "    batch_size=32, shuffle=True,pin_memory=True,num_workers=8)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    ImageFolder(\"Brain_Tumor_Datasets_Classified\\\\test\",transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   \n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])),\n",
    "    batch_size=32, shuffle=True,pin_memory=True,num_workers=8)\n"
   ],
   "id": "6fccdbe73085d7bd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:49:42.471739Z",
     "start_time": "2024-06-04T19:13:44.253406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### Train model\n",
    "train_loss = []\n",
    "train_accuary = []\n",
    "test_loss = []\n",
    "test_accuary = []\n",
    "\n",
    "num_epochs = 160\n",
    "start_time = time.time()  \n",
    "for epoch in range(num_epochs):  \n",
    "    print(\"Epoch {} running\".format(epoch))  \n",
    "    model.train()  \n",
    "    running_loss = 0.  \n",
    "    running_corrects = 0\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataloader.dataset) * 100.\n",
    "\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuary.append(epoch_acc)\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch + 1, epoch_loss, epoch_acc,\n",
    "                                                                       time.time() - start_time))\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 0 or epoch==num_epochs:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "            epoch_loss = running_loss / len(test_dataloader.dataset)\n",
    "            epoch_acc = running_corrects / len(test_dataloader.dataset) * 100.\n",
    "          \n",
    "            test_loss.append(epoch_loss)\n",
    "            test_accuary.append(epoch_acc)\n",
    "       \n",
    "\n",
    "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch + 1, epoch_loss, epoch_acc,\n",
    "                                                                          time.time() - start_time))\n",
    "        torch.save(model.state_dict(), f\"ModelDumps\\\\resnet{epoch}.pth\")"
   ],
   "id": "17d8b2ab707b6a64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 running\n",
      "[Train #1] Loss: 0.0016 Acc: 98.1887% Time: 39.4932s\n",
      "[Test #1] Loss: 0.0017 Acc: 98.6135% Time: 60.9775s\n",
      "Epoch 1 running\n",
      "[Train #2] Loss: 0.0020 Acc: 97.5656% Time: 100.2456s\n",
      "Epoch 2 running\n",
      "[Train #3] Loss: 0.0018 Acc: 97.8264% Time: 139.6828s\n",
      "Epoch 3 running\n",
      "[Train #4] Loss: 0.0016 Acc: 97.9278% Time: 178.7647s\n",
      "[Test #4] Loss: 0.0018 Acc: 98.7868% Time: 200.5402s\n",
      "Epoch 4 running\n",
      "[Train #5] Loss: 0.0014 Acc: 98.4495% Time: 239.7035s\n",
      "Epoch 5 running\n",
      "[Train #6] Loss: 0.0018 Acc: 97.8844% Time: 279.4456s\n",
      "Epoch 6 running\n",
      "[Train #7] Loss: 0.0017 Acc: 98.0438% Time: 318.5111s\n",
      "[Test #7] Loss: 0.0013 Acc: 98.9601% Time: 339.8024s\n",
      "Epoch 7 running\n",
      "[Train #8] Loss: 0.0018 Acc: 97.9568% Time: 378.0259s\n",
      "Epoch 8 running\n",
      "[Train #9] Loss: 0.0018 Acc: 98.0003% Time: 416.0800s\n",
      "Epoch 9 running\n",
      "[Train #10] Loss: 0.0019 Acc: 97.8699% Time: 455.9475s\n",
      "[Test #10] Loss: 0.0015 Acc: 98.8446% Time: 477.2941s\n",
      "Epoch 10 running\n",
      "[Train #11] Loss: 0.0017 Acc: 97.9568% Time: 515.9702s\n",
      "Epoch 11 running\n",
      "[Train #12] Loss: 0.0018 Acc: 97.9858% Time: 553.9612s\n",
      "Epoch 12 running\n",
      "[Train #13] Loss: 0.0015 Acc: 98.2756% Time: 592.1626s\n",
      "[Test #13] Loss: 0.0015 Acc: 98.8446% Time: 613.1031s\n",
      "Epoch 13 running\n",
      "[Train #14] Loss: 0.0017 Acc: 97.9278% Time: 651.1332s\n",
      "Epoch 14 running\n",
      "[Train #15] Loss: 0.0017 Acc: 97.8699% Time: 689.1561s\n",
      "Epoch 15 running\n",
      "[Train #16] Loss: 0.0019 Acc: 97.7539% Time: 727.3529s\n",
      "[Test #16] Loss: 0.0024 Acc: 97.9203% Time: 748.5950s\n",
      "Epoch 16 running\n",
      "[Train #17] Loss: 0.0015 Acc: 98.2321% Time: 788.7489s\n",
      "Epoch 17 running\n",
      "[Train #18] Loss: 0.0018 Acc: 97.9858% Time: 827.8119s\n",
      "Epoch 18 running\n",
      "[Train #19] Loss: 0.0016 Acc: 98.1887% Time: 866.9616s\n",
      "[Test #19] Loss: 0.0056 Acc: 96.8226% Time: 887.8180s\n",
      "Epoch 19 running\n",
      "[Train #20] Loss: 0.0015 Acc: 98.2321% Time: 925.8385s\n",
      "Epoch 20 running\n",
      "[Train #21] Loss: 0.0017 Acc: 98.1452% Time: 963.8759s\n",
      "Epoch 21 running\n",
      "[Train #22] Loss: 0.0015 Acc: 98.3626% Time: 1001.8328s\n",
      "[Test #22] Loss: 0.0013 Acc: 98.7291% Time: 1022.7803s\n",
      "Epoch 22 running\n",
      "[Train #23] Loss: 0.0017 Acc: 98.1017% Time: 1061.5775s\n",
      "Epoch 23 running\n",
      "[Train #24] Loss: 0.0015 Acc: 98.2611% Time: 1100.8150s\n",
      "Epoch 24 running\n",
      "[Train #25] Loss: 0.0017 Acc: 97.9568% Time: 1140.5077s\n",
      "[Test #25] Loss: 0.0044 Acc: 96.7649% Time: 1161.5727s\n",
      "Epoch 25 running\n",
      "[Train #26] Loss: 0.0016 Acc: 98.2321% Time: 1200.1891s\n",
      "Epoch 26 running\n",
      "[Train #27] Loss: 0.0014 Acc: 98.3770% Time: 1238.1102s\n",
      "Epoch 27 running\n",
      "[Train #28] Loss: 0.0017 Acc: 98.1887% Time: 1279.7617s\n",
      "[Test #28] Loss: 0.0019 Acc: 98.5557% Time: 1301.3582s\n",
      "Epoch 28 running\n",
      "[Train #29] Loss: 0.0020 Acc: 97.8699% Time: 1340.7327s\n",
      "Epoch 29 running\n",
      "[Train #30] Loss: 0.0017 Acc: 98.0438% Time: 1379.9990s\n",
      "Epoch 30 running\n",
      "[Train #31] Loss: 0.0016 Acc: 97.9568% Time: 1419.3324s\n",
      "[Test #31] Loss: 0.0020 Acc: 98.3247% Time: 1440.7702s\n",
      "Epoch 31 running\n",
      "[Train #32] Loss: 0.0014 Acc: 98.3046% Time: 1480.3129s\n",
      "Epoch 32 running\n",
      "[Train #33] Loss: 0.0016 Acc: 98.1597% Time: 1519.9159s\n",
      "Epoch 33 running\n",
      "[Train #34] Loss: 0.0016 Acc: 97.9713% Time: 1559.1373s\n",
      "[Test #34] Loss: 0.0028 Acc: 97.4581% Time: 1580.5533s\n",
      "Epoch 34 running\n",
      "[Train #35] Loss: 0.0015 Acc: 98.3191% Time: 1619.8523s\n",
      "Epoch 35 running\n",
      "[Train #36] Loss: 0.0014 Acc: 98.5364% Time: 1658.3512s\n",
      "Epoch 36 running\n",
      "[Train #37] Loss: 0.0015 Acc: 98.1307% Time: 1696.1860s\n",
      "[Test #37] Loss: 0.0017 Acc: 98.6713% Time: 1717.3297s\n",
      "Epoch 37 running\n",
      "[Train #38] Loss: 0.0017 Acc: 98.1452% Time: 1755.1457s\n",
      "Epoch 38 running\n",
      "[Train #39] Loss: 0.0015 Acc: 98.2756% Time: 1792.9452s\n",
      "Epoch 39 running\n",
      "[Train #40] Loss: 0.0016 Acc: 98.1017% Time: 1830.9171s\n",
      "[Test #40] Loss: 0.0063 Acc: 93.8186% Time: 1851.8652s\n",
      "Epoch 40 running\n",
      "[Train #41] Loss: 0.0018 Acc: 97.9713% Time: 1889.7143s\n",
      "Epoch 41 running\n",
      "[Train #42] Loss: 0.0013 Acc: 98.4350% Time: 1927.5003s\n",
      "Epoch 42 running\n",
      "[Train #43] Loss: 0.0016 Acc: 98.2466% Time: 1966.5613s\n",
      "[Test #43] Loss: 0.0014 Acc: 99.3068% Time: 1987.6646s\n",
      "Epoch 43 running\n",
      "[Train #44] Loss: 0.0016 Acc: 98.1017% Time: 2025.7360s\n",
      "Epoch 44 running\n",
      "[Train #45] Loss: 0.0013 Acc: 98.3770% Time: 2064.5539s\n",
      "Epoch 45 running\n",
      "[Train #46] Loss: 0.0014 Acc: 98.3915% Time: 2103.0278s\n",
      "[Test #46] Loss: 0.0013 Acc: 99.1334% Time: 2124.0314s\n",
      "Epoch 46 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x00000153CB001C60>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MKP_Desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\MKP_Desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"C:\\Users\\MKP_Desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MKP_Desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 110, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 27\u001B[0m\n\u001B[0;32m     25\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     26\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 27\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m     running_corrects \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(preds \u001B[38;5;241m==\u001B[39m labels\u001B[38;5;241m.\u001B[39mdata)\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     29\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m running_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_dataloader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
